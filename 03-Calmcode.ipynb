{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciKit Learn for Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this specific version of scikit learn:\n",
    "!pip install --upgrade scikit-learn==0.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting numpy<2.0,>=1.19.5 (from scikit-learn)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.12.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Using cached scipy-1.12.0-cp311-cp311-win_amd64.whl (46.2 MB)\n",
      "Using cached threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-1.3.2 numpy-1.26.4 scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.3.0\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start with data-> split data into x and y. x represents everything using to make a prediction. y represents the target we are trying to predict.\n",
    "2. give to model & model learns->\n",
    "3. model makes predictions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "X, y = load_boston(return_x_y=True) #one array for house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 phases:\n",
    "    - Create the model <- python object\n",
    "    - Model learns from data <- .fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "mod = KNeighborRegressor()\n",
    "mod.fit(X,y) #will learn from the data and make a prediction. Number of predictions should be equal to number of rows in the X array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "mod = LinearRegression()\n",
    "mod.fit(X,y)\n",
    "#Basically all api's are set up the same. Call a function and fit the model for the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with true values and predicted value\n",
    "from matplotlib.pylab as plt\n",
    "pred = mod.predict(X)\n",
    "plt.scatter(pred,y)\n",
    "#Need to be cautious Nwhen comparing the variables, may be on different scales so assumptions may not always be correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defintion: Pipelines bundle preprocessing and modeling steps so you can use them as a single step in your machine learning workflow.\n",
    "\n",
    "#In the case of different units for variables, Scale the X before passing data into knn\n",
    "#   - The \"model\" will include the scaling, and scikit learn is set up to .fit and .predict from the entire pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline #allows you to train processing steps after eachother \n",
    "\n",
    "\n",
    "#under mod fit\n",
    "pip = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"model\", KNeigborsRegressor())])\n",
    "\n",
    "pipe.fit(X,y)\n",
    "pred = pipe.predict(X) \n",
    "plt.scatter(pred,y) #creates a better, scaled scatter plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#We want to avoid using an orginal data point as apart of the predictions.\n",
    "\n",
    "pip = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"model\", KNeigborsRegressor(n_neighbors=1))]) \n",
    "\n",
    "pipe.fit(X,y)\n",
    "pred = pipe.predict(X) \n",
    "plt.scatter(pred,y) # the nearest neighbor is the original data point(n=1) so of course it will be a perfectly correlated line.\n",
    "\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the pipeline and we have some settings such that the model gives the best predicitions. \n",
    "    - We need to avoid predicitions on the same data that we are working on\n",
    "To avoid any issues, split the X into three parts and duplicate the variable three times. One for predictions and two for training. Essentially to test model outputs for each \"side\" of the data and avoid prediciting on data used during training.\n",
    "\n",
    "\n",
    "      fit() = train\n",
    "    \n",
    "      predict() = predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "GridSearchCV (object) - you can give it a pipeline and a grid(ie; number of neighbors 1-10) to conduct cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "GridSearchCV(estimator=pipe,\n",
    "    param_grid={'model_n_neighbors':[1,2,3,4,5,6,7,8,9,10]}, cv=3) #estimator has a .fit and .predict,\n",
    "mod.fit(X,y) \n",
    "mod.cv_results_ # for every cross validation it will keep track of the numbers in a dictionary format. Putting it into a df you can see training time, score, and rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-learn the wrong way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IT IS ALWAYS IMPORTANT TO INSPECT THE DATASET BEFORE PREDICTIONS\n",
    "print(load_bston()['DESCR']) # has an offensive and biased data column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a danger in using GRID-SEARCH \n",
    "    - Optimisic insights and \"well\" performing models can give you a blind spot in your development \n",
    "    - The data and output of a machine learning algorithim are the users responsibility "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cookiecutter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Optimizing the base for all of your future projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cookiecutter \n",
    "- json file\n",
    "- folder and directory structure for automatic filling \n",
    "\n",
    "In a venv create a file called cookiecutter.json \n",
    "insert\n",
    "{\n",
    "    \"project\":\"project\"\n",
    "}\n",
    "create a folder called {{cookiecutter.project}} \n",
    "    - inside folder create a readme.md \n",
    "    - insert #readme of {{cookiecutter.project}}\n",
    "\n",
    "cookiecutter took the .json file replaced it with \"hello-world\". Will subsequently create a folder called hello-world and a readme.md with hello-world. \n",
    "\n",
    "pip install cookiecutter\n",
    "cookiecutter .\n",
    "#computer will prompt you for an input and type \n",
    "hello-world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding an Author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in cookiecutter .json \n",
    "\n",
    "{\n",
    "    \"project\":\"project\",\n",
    "    \"author\":\"author\"\n",
    "}\n",
    "\n",
    "in readme file for cookiecutter type\n",
    "This package was made by {{cookiecutter.author}}. \n",
    "\n",
    "in terminal type cookiecutter .\n",
    "\n",
    "Ultimately you can use the {{}} as a dunamic field "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create another folder called {{cookiecutter.project_slug}}\n",
    "in the cookiecutter.json type\n",
    "\n",
    "{\n",
    "    \"project\":\"project\",\n",
    "    \"author\":\"author\",\n",
    "    \"project_slug\":\"{{cookiecutter.project.lower().replace(' ','_')}}\"\n",
    "}\n",
    "anything inside \"{{}}\" will be treated as a python string. When you input the project name, it will take into account the rules for the project_slug line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionals and sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want end user to select one option out of a set:\n",
    "in the cookiecutter.json type\n",
    "{\n",
    "    \"project\":\"project\",\n",
    "    \"author\":\"author\",\n",
    "    \"project_slug\":\"{{cookiecutter.project.lower().replace(' ','_')}}\",\n",
    "    :license\": [\"MIT\",\"BSD\"]\n",
    "}\n",
    "\n",
    "in readme \n",
    "add:\n",
    "\n",
    "{%- if cookiecutter.license == \"MIT\" -%}\n",
    "\n",
    "This is an MIT license.\n",
    "\n",
    "{%- elif cookiecutter.license == \"BSD\" -%}\n",
    "\n",
    "This is a BSD license.\n",
    "\n",
    "{% endif %}\n",
    "\n",
    "\n",
    "The using ginja python tool to do templating and syntax  \n",
    "\n",
    "When you run the \"cookiecutter .\" command in terminal you will see the choices for MIT or BSD. \n",
    "\n",
    "in the readme file you will see the answers from the input!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a setup.py \n",
    "\n",
    "from setuptools import setup \n",
    "\n",
    "setup(\n",
    "    name=\"{{cookiecutter.project_slug}}\",\n",
    "    version =\"0.0.1\"\n",
    ")\n",
    "\n",
    "Now running cookiecutter .  in terminal will make the import statements dynamic to what you name the project on the first input statement. \n",
    "\n",
    "This is great for automating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing cookiecutter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can push the cookiecutter.project and cookiecutter.json to gitlab or github. \n",
    "\n",
    "instead of typing cookiecutter ., you can type cookiecutter (link to .git file)\n",
    "\n",
    "Great for not storing locally!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always find other cookiecutters online. \n",
    "Check the [official cookiecutter GitHub]([https://github.com/cookiecutter/cookiecutter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
